{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP:0001324 Muscle weakness\n"
     ]
    }
   ],
   "source": [
    "from HpoDatabase import HpoDatabase\n",
    "db_path = 'hpo_chroma_db'\n",
    "obo_path = 'hp.obo'\n",
    "hpo_db = HpoDatabase(db_path, obo_path)\n",
    "# test query\n",
    "query = \"muscle weakness\"\n",
    "results = hpo_db.query_hpo(query)\n",
    "hpo_id, hpo_name = hpo_db.parse_results(results)\n",
    "print(hpo_id, hpo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18330 HPO terms with synonyms\n"
     ]
    }
   ],
   "source": [
    "# load all synonyms generated by GPT-4o-mini\n",
    "synonym_folder = '/Users/cl3720/Desktop/hpo-parser-fine-tuned-gemini/hpo_synonyms/gpt-4o-mini-2024-07-18'\n",
    "import os\n",
    "import json\n",
    "expanded_hpo_name_dict = {}\n",
    "if os.path.exists(synonym_folder):\n",
    "# load the synonyms from the folder\n",
    "# each file in the folder is a json file with the following format {\"HP:XXXX\": [\"synonym1\", \"synonym2\", \"synonym3\"]}\n",
    "    for file in os.listdir(synonym_folder):\n",
    "        with open(os.path.join(synonym_folder, file), \"r\") as f:\n",
    "            expanded_hpo_name_dict.update(json.load(f))\n",
    "len(expanded_hpo_name_dict)\n",
    "print(f\"There are {len(expanded_hpo_name_dict)} HPO terms with synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No HPO id found for 3.0 LogMAR pinhole test\n"
     ]
    }
   ],
   "source": [
    "# query with synonyms and store the id.\n",
    "import random\n",
    "query_results = {}\n",
    "i = 0\n",
    "for hp_id in expanded_hpo_name_dict:\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processed {i} HPO terms\")       \n",
    "    \n",
    "    # if i > 100:\n",
    "    #     break   \n",
    "    query_results[hp_id] = []\n",
    "    for synonym in expanded_hpo_name_dict[hp_id]:\n",
    "        # create a random indicator p (0,1) to decide whether to query the synonym\n",
    "        p = random.random()\n",
    "        if p > 1:\n",
    "            # takes ~5 minutes to query 500 HPO terms\n",
    "            # on average, it takes 0.6 seconds to query one HPO term\n",
    "            # so it will take 0.6 * 18000 / 3600 = 3 hours to query all HPO terms\n",
    "            continue\n",
    "        results = hpo_db.query_hpo(synonym)\n",
    "        hit_hpo_id, _ = hpo_db.parse_results(results)\n",
    "        if hit_hpo_id:\n",
    "            query_results[hp_id].append(hit_hpo_id)\n",
    "        else:\n",
    "            print(f\"No HPO id found for {synonym}\")\n",
    "            query_results[hp_id].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the query results to a json file\n",
    "# with open('rag_evaluation_query_results.json', 'w') as f:\n",
    "#     json.dump(query_results, f)\n",
    "    \n",
    "# load the query results from the json file\n",
    "with open('rag_evaluation_query_results.json', 'r') as f:\n",
    "    query_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# merge two dictionary by keys\n",
    "\n",
    "# convert expanded_hpo_name_dict into pandas dataframe\n",
    "expanded_hpo_name_df = pd.DataFrame(expanded_hpo_name_dict.items(), columns=['query_hpo_id', 'synonyms'])\n",
    "# convert query_results into pandas dataframe\n",
    "query_results_df = pd.DataFrame(query_results.items(), columns=['query_hpo_id', 'hit_hpo_ids'])\n",
    "# merge the two dataframes\n",
    "merged_df = pd.merge(expanded_hpo_name_df, query_results_df, on='query_hpo_id')\n",
    "# expand the hit_hpo_ids into multiple rows\n",
    "merged_df = merged_df.explode(['synonyms','hit_hpo_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.41828696126568465\n",
      "At least 1 hit accuracy: 0.7346426623022367\n",
      "At least 2 hit accuracy: 0.5433169667212221\n",
      "At least 3 hit accuracy: 0.3880523731587561\n",
      "At least 4 hit accuracy: 0.26677577741407527\n",
      "At least 5 hit accuracy: 0.15864702673213313\n"
     ]
    }
   ],
   "source": [
    "# turn off DeprecationWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# overall accuracy query_hpo_id == hit_hpo_ids\n",
    "overall_accuracy = (merged_df.query_hpo_id == merged_df.hit_hpo_ids).mean()\n",
    "print(f\"Overall accuracy: {overall_accuracy}\")\n",
    "# by query_hpo_id at least one hit_hpo_ids == query_hpo_id\n",
    "for at_leat_i_hit in range(1, 6):\n",
    "    at_least_x_hit_accuracy = merged_df.groupby('query_hpo_id').apply(lambda x: (x.query_hpo_id == x.hit_hpo_ids).value_counts().get(True, 0) >= at_leat_i_hit).mean()\n",
    "    print(f\"At least {at_leat_i_hit} hit accuracy: {at_least_x_hit_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HPO ontology\n",
    "from HpoFactory import HpoFactory\n",
    "hpoF = HpoFactory()\n",
    "hpo_tree = hpoF.build_hpo_tree()\n",
    "hpo_ancestors = hpoF.get_hpo_ancestors(hpo_tree)\n",
    "hpo_levels = hpoF.get_hpo_levels(hpo_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_ancestors_df = pd.DataFrame(hpo_ancestors.items(), columns=['hpo_id', 'ancestor'])\n",
    "# add hp_id to the ancestor list in the ancestor column\n",
    "hpo_ancestors_df['ancestor'] = hpo_ancestors_df.apply(lambda x: [x.hpo_id] + x.ancestor, axis=1)\n",
    "# hpo_ancestors_df = hpo_ancestors_df.explode('ancestor')\n",
    "# hpo_ancestors_df.rename(columns={'hpo_id': 'descendant'}, inplace=True)\n",
    "# # group by ancestor and make a list of descendants\n",
    "# hpo_ancestors_df = hpo_ancestors_df.groupby('ancestor').descendant.apply(list).reset_index()\n",
    "hpo_ancestors_df.rename(columns={'hpo_id': 'hit_hpo_ids'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by ancestors: 0.524\n",
      "At least 1 hit accuracy by ancestors: 0.88\n",
      "At least 2 hit accuracy by ancestors: 0.69\n",
      "At least 3 hit accuracy by ancestors: 0.52\n",
      "At least 4 hit accuracy by ancestors: 0.34\n",
      "At least 5 hit accuracy by ancestors: 0.19\n"
     ]
    }
   ],
   "source": [
    "# accuracy counted by ancestors\n",
    "merged_ancestor_df = hpo_ancestors_df.merge(merged_df, how='right')\n",
    "# generate a column to indicate whether the hit_hpo_ids is in the ancestor list\n",
    "merged_ancestor_df['query_is_ancestor'] = merged_ancestor_df.apply(\n",
    "    lambda x: isinstance(x['ancestor'], (list, set)) and x['query_hpo_id'] in x['ancestor'],\n",
    "    axis=1\n",
    ")# To avoid TypeError: argument of type 'float' is not iterable\n",
    "# accuracy by ancestors\n",
    "ancestor_accuracy = merged_ancestor_df.query_is_ancestor.mean()\n",
    "print(f\"Accuracy by ancestors: {ancestor_accuracy}\")\n",
    "# by query_hpo_id at least one hit_hpo_ids == ancestor\n",
    "for at_leat_i_hit in range(1, 6):\n",
    "    at_least_x_hit_accuracy = merged_ancestor_df.groupby('query_hpo_id').apply(lambda x: x.query_is_ancestor.value_counts().get(True, 0) >= at_leat_i_hit).mean()\n",
    "    print(f\"At least {at_leat_i_hit} hit accuracy by ancestors: {at_least_x_hit_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with string based search\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

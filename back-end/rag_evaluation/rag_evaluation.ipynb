{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules in the parent directory\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# turn off DeprecationWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sys.path.append('..')\n",
    "obo_path = '../hp.obo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18330 HPO terms with synonyms\n"
     ]
    }
   ],
   "source": [
    "# load all synonyms generated by GPT-4o-mini\n",
    "synonym_folder = '/Users/cl3720/Desktop/hpo-parser-fine-tuned-gemini/hpo_synonyms/gpt-4o-mini-2024-07-18'\n",
    "expanded_hpo_name_dict = {}\n",
    "if os.path.exists(synonym_folder):\n",
    "# load the synonyms from the folder\n",
    "# each file in the folder is a json file with the following format {\"HP:XXXX\": [\"synonym1\", \"synonym2\", \"synonym3\"]}\n",
    "    for file in os.listdir(synonym_folder):\n",
    "        with open(os.path.join(synonym_folder, file), \"r\") as f:\n",
    "            expanded_hpo_name_dict.update(json.load(f))\n",
    "len(expanded_hpo_name_dict)\n",
    "print(f\"There are {len(expanded_hpo_name_dict)} HPO terms with synonyms\")\n",
    "# load the HPO ontology\n",
    "from HpoFactory import HpoFactory\n",
    "hpoF = HpoFactory(obo_path)\n",
    "hpo_tree = hpoF.build_hpo_tree()\n",
    "hpo_ancestors = hpoF.get_hpo_ancestors(hpo_tree)\n",
    "hpo_levels = hpoF.get_hpo_levels(hpo_tree)\n",
    "hpo_ancestors_df = pd.DataFrame(hpo_ancestors.items(), columns=['hpo_id', 'ancestor'])\n",
    "# add hp_id to the ancestor list in the ancestor column\n",
    "hpo_ancestors_df['ancestor'] = hpo_ancestors_df.apply(lambda x: [x.hpo_id] + x.ancestor, axis=1)\n",
    "hpo_ancestors_df.rename(columns={'hpo_id': 'hit_hpo_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance in Top 1 exactly matched results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json = './rag_evaluation_query_results_top1_whoosh.json'    \n",
    "# load the query results from the json file\n",
    "with open(result_json, 'r') as f:\n",
    "    query_results = json.load(f)\n",
    "\n",
    "# # # top 5 also contains top 1 results\n",
    "# result_json = './rag_evaluation_query_results_top5_text-embedding-3-large.json'\n",
    "# # load the query results from the json file\n",
    "# with open(result_json, 'r') as f:\n",
    "#     query_results = json.load(f)\n",
    "#     # convert to top 1 results\n",
    "#     query_results = {k: [v[i]['parsed_results'][0]['hpo_id'] if i < len(v) else None for i in range(5)] for k, v in query_results.items()}\n",
    "#     # for some reason, the query results are not the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.06\n",
      "At least 1 hit accuracy: 0.218603\n",
      "At least 2 hit accuracy: 0.054610\n",
      "At least 3 hit accuracy: 0.012220\n",
      "At least 4 hit accuracy: 0.002728\n",
      "At least 5 hit accuracy: 0.000327\n"
     ]
    }
   ],
   "source": [
    "# merge two dictionary by keys\n",
    "# convert expanded_hpo_name_dict into pandas dataframe\n",
    "expanded_hpo_name_df = pd.DataFrame(expanded_hpo_name_dict.items(), columns=['query_hpo_id', 'synonyms'])\n",
    "# convert query_results into pandas dataframe\n",
    "query_results_df = pd.DataFrame(query_results.items(), columns=['query_hpo_id', 'hit_hpo_id'])\n",
    "# merge the two dataframes\n",
    "merged_df = pd.merge(expanded_hpo_name_df, query_results_df, on='query_hpo_id')\n",
    "# expand the hit_hpo_ids into multiple rows\n",
    "merged_df = merged_df.explode(['synonyms','hit_hpo_id'])\n",
    "# overall accuracy query_hpo_id == hit_hpo_ids\n",
    "overall_accuracy = (merged_df.query_hpo_id == merged_df.hit_hpo_id).mean()\n",
    "# round 2 decimal places\n",
    "print(f\"Overall accuracy: {overall_accuracy:.2f}\")\n",
    "# by query_hpo_id at least one hit_hpo_ids == query_hpo_id\n",
    "for at_leat_i_hit in range(1, 6):\n",
    "    at_least_x_hit_accuracy = merged_df.groupby('query_hpo_id').apply(lambda x: (x.query_hpo_id == x.hit_hpo_id).value_counts().get(True, 0) >= at_leat_i_hit).mean()\n",
    "    print(f\"At least {at_leat_i_hit} hit accuracy: {at_least_x_hit_accuracy:1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_hpo_id</th>\n",
       "      <th>hit_hpo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP:0030429</td>\n",
       "      <td>[None, None, HP:0030429, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP:0004875</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP:0032414</td>\n",
       "      <td>[HP:0031991, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP:5200239</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP:0100607</td>\n",
       "      <td>[None, HP:0032149, None, HP:0003710, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>HP:0030778</td>\n",
       "      <td>[HP:0030778, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18326</th>\n",
       "      <td>HP:0011025</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18327</th>\n",
       "      <td>HP:0008204</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18328</th>\n",
       "      <td>HP:0030282</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18329</th>\n",
       "      <td>HP:0000634</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_hpo_id                                  hit_hpo_id\n",
       "0       HP:0030429        [None, None, HP:0030429, None, None]\n",
       "1       HP:0004875              [None, None, None, None, None]\n",
       "2       HP:0032414        [HP:0031991, None, None, None, None]\n",
       "3       HP:5200239              [None, None, None, None, None]\n",
       "4       HP:0100607  [None, HP:0032149, None, HP:0003710, None]\n",
       "...            ...                                         ...\n",
       "18325   HP:0030778        [HP:0030778, None, None, None, None]\n",
       "18326   HP:0011025              [None, None, None, None, None]\n",
       "18327   HP:0008204              [None, None, None, None, None]\n",
       "18328   HP:0030282              [None, None, None, None, None]\n",
       "18329   HP:0000634              [None, None, None, None, None]\n",
       "\n",
       "[18330 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance in Top 1 desendants matched results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by ancestors: 0.639356\n",
      "At least 1 hit accuracy by ancestors: 0.911348\n",
      "At least 2 hit accuracy by ancestors: 0.797054\n",
      "At least 3 hit accuracy by ancestors: 0.660011\n",
      "At least 4 hit accuracy by ancestors: 0.503219\n",
      "At least 5 hit accuracy by ancestors: 0.325150\n"
     ]
    }
   ],
   "source": [
    "# accuracy counted by ancestors\n",
    "merged_ancestor_df = hpo_ancestors_df.merge(merged_df, how='right')\n",
    "# generate a column to indicate whether the hit_hpo_ids is in the ancestor list\n",
    "merged_ancestor_df['query_is_ancestor'] = merged_ancestor_df.apply(\n",
    "    lambda x: isinstance(x['ancestor'], (list, set)) and x['query_hpo_id'] in x['ancestor'],\n",
    "    axis=1\n",
    ")# To avoid TypeError: argument of type 'float' is not iterable\n",
    "# accuracy by ancestors\n",
    "ancestor_accuracy = merged_ancestor_df.query_is_ancestor.mean()\n",
    "print(f\"Accuracy by ancestors: {ancestor_accuracy:2f}\")\n",
    "# by query_hpo_id at least one hit_hpo_ids == ancestor\n",
    "for at_leat_i_hit in range(1, 6):\n",
    "    at_least_x_hit_accuracy = merged_ancestor_df.groupby('query_hpo_id').apply(lambda x: x.query_is_ancestor.value_counts().get(True, 0) >= at_leat_i_hit).mean()\n",
    "    print(f\"At least {at_leat_i_hit} hit accuracy by ancestors: {at_least_x_hit_accuracy:2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance in Top 5 exactly matched results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 match\n",
    "result_json = './rag_evaluation_query_results_top25_text-embedding-3-large.json'\n",
    "# load the query results from the json file\n",
    "with open(result_json, 'r') as f:\n",
    "    query_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 60.94%\n",
      "Top 2 accuracy: 72.79%\n",
      "Top 3 accuracy: 78.40%\n",
      "Top 4 accuracy: 81.81%\n",
      "Top 5 accuracy: 84.11%\n"
     ]
    }
   ],
   "source": [
    "# merge two dictionary by keys\n",
    "# convert expanded_hpo_name_dict into pandas dataframe\n",
    "expanded_hpo_name_df = pd.DataFrame(expanded_hpo_name_dict.items(), columns=['query_hpo_id', 'synonyms'])\n",
    "expanded_hpo_name_df = expanded_hpo_name_df.explode('synonyms')\n",
    "expanded_hpo_name_df.rename(columns={'synonyms': 'query_synonym'}, inplace=True)\n",
    "# convert query_results into pandas dataframe\n",
    "# Flatten the dictionary\n",
    "rows = []\n",
    "for key, value in query_results.items():\n",
    "    for entry in value:\n",
    "        synonym = entry.get('synonym', '')\n",
    "        for result in entry.get('parsed_results', []):\n",
    "            rows.append({\n",
    "                'query_hpo_id': key,\n",
    "                'query_synonym': synonym,\n",
    "                'hit_hpo_id': result['hpo_id'],\n",
    "                'hit_hpo_name': result['hpo_name'],\n",
    "                'top_k': result['top_k'],\n",
    "                'distance': result['distance']\n",
    "            })\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "query_results_df = pd.DataFrame(rows)\n",
    "# query_results_df = pd.DataFrame(query_results.items(), columns=['query_hpo_id', 'hit_hpo_objects'])\n",
    "# merge the two dataframes\n",
    "merged_df = pd.merge(expanded_hpo_name_df, query_results_df, on=['query_hpo_id','query_synonym'])\n",
    "# expand the hit_hpo_ids into multiple rows\n",
    "total_pairs = merged_df.groupby(['query_hpo_id', 'query_synonym']).ngroups\n",
    "# Load into pandas DataFrame\n",
    "# Filter the DataFrame based on the conditions\n",
    "for k in range(25):\n",
    "    filtered_df = merged_df[(merged_df['top_k'] <= k) & (merged_df['query_hpo_id'] == merged_df['hit_hpo_id'])]\n",
    "    # Count the unique \"query_hpo_id, query_synonym\" pairs\n",
    "    count = filtered_df.groupby(['query_hpo_id', 'query_synonym']).ngroups\n",
    "    # Calculate the percentage\n",
    "    percentage = (count / total_pairs) * 100\n",
    "    print(f\"Top {k+1} accuracy: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance in Top 5 descendants matched results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 91649\n",
      "Top 1 accuracy: 63.94%\n",
      "Top 2 accuracy: 74.24%\n",
      "Top 3 accuracy: 78.89%\n",
      "Top 4 accuracy: 81.79%\n",
      "Top 5 accuracy: 83.72%\n"
     ]
    }
   ],
   "source": [
    "# accuracy counted by ancestors\n",
    "merged_ancestor_df = hpo_ancestors_df.merge(merged_df, how='right')\n",
    "# generate a column to indicate whether the hit_hpo_ids is in the ancestor list\n",
    "merged_ancestor_df['query_is_ancestor'] = merged_ancestor_df.apply(\n",
    "    lambda x: isinstance(x['ancestor'], (list, set)) and x['query_hpo_id'] in x['ancestor'],\n",
    "    axis=1\n",
    ")# expand the hit_hpo_ids into multiple rows\n",
    "total_pairs = merged_ancestor_df.groupby(['query_hpo_id', 'query_synonym']).ngroups\n",
    "print(f\"Total pairs: {total_pairs}\")\n",
    "# Load into pandas DataFrame\n",
    "# Filter the DataFrame based on the conditions\n",
    "for k in range(5):\n",
    "    filtered_df = merged_ancestor_df[(merged_ancestor_df['top_k'] <= k) & (merged_ancestor_df['query_is_ancestor'] == True)]\n",
    "    # Count the unique \"query_hpo_id, query_synonym\" pairs\n",
    "    count = filtered_df.groupby(['query_hpo_id', 'query_synonym']).ngroups\n",
    "    # Calculate the percentage\n",
    "    percentage = (count / total_pairs) * 100\n",
    "    print(f\"Top {k+1} accuracy: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['distance'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot distantce distribution by query_is_ancestor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m for_plot_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_ancestor_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_is_ancestor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m for_plot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_is_ancestor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m for_plot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_is_ancestor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mviolinplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_is_ancestor\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mfor_plot_df)\n",
      "File \u001b[0;32m~/Desktop/Doc2Hpo2.0/back-end/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Doc2Hpo2.0/back-end/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Doc2Hpo2.0/back-end/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['distance'] not in index\""
     ]
    }
   ],
   "source": [
    "# plot distantce distribution by query_is_ancestor\n",
    "for_plot_df = merged_ancestor_df[['query_is_ancestor','distance']]\n",
    "for_plot_df['query_is_ancestor'] = for_plot_df['query_is_ancestor'].astype(str)\n",
    "sns.violinplot(x='query_is_ancestor', y='distance', data=for_plot_df)\n",
    "plt.show()\n",
    "# do t test to show the differences\n",
    "from scipy.stats import ttest_ind\n",
    "query_is_ancestor = for_plot_df.query('query_is_ancestor == \"True\"')['distance']\n",
    "query_is_not_ancestor = for_plot_df.query('query_is_ancestor == \"False\"')['distance']\n",
    "# print summary statistics\n",
    "print(query_is_ancestor.describe())\n",
    "print(query_is_not_ancestor.describe())\n",
    "t_test = ttest_ind(query_is_ancestor, query_is_not_ancestor)\n",
    "print(t_test)\n",
    "# do mannwhitneyu test to show the differences\n",
    "from scipy.stats import mannwhitneyu\n",
    "mannwhitneyu_test = mannwhitneyu(query_is_ancestor, query_is_not_ancestor)\n",
    "print(mannwhitneyu_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with GPT-4's reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all sampled hp_ids from \n",
    "nonir_gpt_response_folder = './nonir_gpt_response'\n",
    "# loop through all files in the folder\n",
    "all_nonir_gpt_responses = []\n",
    "for file in os.listdir(nonir_gpt_response_folder):\n",
    "    with open(os.path.join(nonir_gpt_response_folder, file), \"r\") as f:\n",
    "        gpt_response_json = json.load(f)\n",
    "        all_nonir_gpt_responses.append(gpt_response_json)\n",
    "# convert to pandas dataframe\n",
    "nonir_gpt_responses_df = pd.DataFrame(all_nonir_gpt_responses)\n",
    "nonir_gpt_responses_df['gpt_top_k'] = nonir_gpt_responses_df['gpt_response'] - 1\n",
    "# subset merged_df by nonir_gpt_responses_df's query_hpo_id and query_synonym\n",
    "ir_subset_df = merged_df[merged_df['query_hpo_id'].isin(nonir_gpt_responses_df['query_hpo_id']) & merged_df['query_synonym'].isin(nonir_gpt_responses_df['query_synonym'])]\n",
    "# # merge ir_merged_df with nonir_gpt_responses_df\n",
    "# gpt_ir_comparison_df = ir_merged_df.merge(nonir_gpt_responses_df, on=['query_hpo_id', 'query_synonym'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT top 1 accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# GPT top 1 accuracy \n",
    "gpt_top1_accuracy = (nonir_gpt_responses_df['query_hpo_id'] == nonir_gpt_responses_df['gpt_hit_hpo_id']).mean()\n",
    "print(f\"GPT top 1 accuracy: {gpt_top1_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR top 1 accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "# IR top 1 accuracy\n",
    "ir_subset_df_top1 = ir_subset_df[ir_subset_df['top_k'] == 0]    \n",
    "ir_top1_accuracy = (ir_subset_df_top1['query_hpo_id'] == ir_subset_df_top1['hit_hpo_id']).mean()\n",
    "print(f\"IR top 1 accuracy: {ir_top1_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sampled 100 pairs for human evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_hpo_id</th>\n",
       "      <th>query_synonym</th>\n",
       "      <th>hit_hpo_id</th>\n",
       "      <th>hit_hpo_name</th>\n",
       "      <th>top_k</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14205</th>\n",
       "      <td>HP:0032681</td>\n",
       "      <td>Focal seizure with awareness</td>\n",
       "      <td>HP:0002349</td>\n",
       "      <td>Focal aware seizure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14206</th>\n",
       "      <td>HP:0032681</td>\n",
       "      <td>Focal seizure with awareness</td>\n",
       "      <td>HP:0032681</td>\n",
       "      <td>Focal aware cognitive seizure</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>HP:0032681</td>\n",
       "      <td>Focal seizure with awareness</td>\n",
       "      <td>HP:0032754</td>\n",
       "      <td>Focal aware sensory seizure</td>\n",
       "      <td>2</td>\n",
       "      <td>0.571813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14208</th>\n",
       "      <td>HP:0032681</td>\n",
       "      <td>Focal seizure with awareness</td>\n",
       "      <td>HP:0020217</td>\n",
       "      <td>Focal aware motor seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0.618296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14209</th>\n",
       "      <td>HP:0032681</td>\n",
       "      <td>Focal seizure with awareness</td>\n",
       "      <td>HP:0032864</td>\n",
       "      <td>Focal aware sensory seizure with auditory feat...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.619292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458050</th>\n",
       "      <td>HP:0100556</td>\n",
       "      <td>Unilateral atrophy</td>\n",
       "      <td>HP:0008717</td>\n",
       "      <td>Unilateral renal atrophy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.694840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458051</th>\n",
       "      <td>HP:0100556</td>\n",
       "      <td>Unilateral atrophy</td>\n",
       "      <td>HP:0100557</td>\n",
       "      <td>Hemiatrophy of lower limb</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458052</th>\n",
       "      <td>HP:0100556</td>\n",
       "      <td>Unilateral atrophy</td>\n",
       "      <td>HP:0100558</td>\n",
       "      <td>Hemiatrophy of upper limb</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458053</th>\n",
       "      <td>HP:0100556</td>\n",
       "      <td>Unilateral atrophy</td>\n",
       "      <td>HP:0100556</td>\n",
       "      <td>Hemiatrophy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.848824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458054</th>\n",
       "      <td>HP:0100556</td>\n",
       "      <td>Unilateral atrophy</td>\n",
       "      <td>HP:0011331</td>\n",
       "      <td>Hemifacial atrophy</td>\n",
       "      <td>4</td>\n",
       "      <td>0.862918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query_hpo_id                 query_synonym  hit_hpo_id  \\\n",
       "14205    HP:0032681  Focal seizure with awareness  HP:0002349   \n",
       "14206    HP:0032681  Focal seizure with awareness  HP:0032681   \n",
       "14207    HP:0032681  Focal seizure with awareness  HP:0032754   \n",
       "14208    HP:0032681  Focal seizure with awareness  HP:0020217   \n",
       "14209    HP:0032681  Focal seizure with awareness  HP:0032864   \n",
       "...             ...                           ...         ...   \n",
       "458050   HP:0100556            Unilateral atrophy  HP:0008717   \n",
       "458051   HP:0100556            Unilateral atrophy  HP:0100557   \n",
       "458052   HP:0100556            Unilateral atrophy  HP:0100558   \n",
       "458053   HP:0100556            Unilateral atrophy  HP:0100556   \n",
       "458054   HP:0100556            Unilateral atrophy  HP:0011331   \n",
       "\n",
       "                                             hit_hpo_name  top_k  distance  \n",
       "14205                                 Focal aware seizure      0  0.523132  \n",
       "14206                       Focal aware cognitive seizure      1  0.571581  \n",
       "14207                         Focal aware sensory seizure      2  0.571813  \n",
       "14208                           Focal aware motor seizure      3  0.618296  \n",
       "14209   Focal aware sensory seizure with auditory feat...      4  0.619292  \n",
       "...                                                   ...    ...       ...  \n",
       "458050                           Unilateral renal atrophy      0  0.694840  \n",
       "458051                          Hemiatrophy of lower limb      1  0.811439  \n",
       "458052                          Hemiatrophy of upper limb      2  0.830153  \n",
       "458053                                        Hemiatrophy      3  0.848824  \n",
       "458054                                 Hemifacial atrophy      4  0.862918  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
